# Transformer 学习

## 一、注意力机制

### 1.1 向量点积&语义相似度

✨ **注意力机制的核心：向量相似度 -> 语义相似度**

因为机器是看不懂文字的，如果想让机器去理解每个词语的意思，就需要一个模型`（Embedding模型）`把这些词语`（token）`转化成 `向量`

> 对于中文来讲，一个 token 可以是一个词语，也可以是一个字，它是具有独立语义的单位

<img src="./assets/image-20260201192219603.png" alt="image-20260201192219603" width="80%"/>

`「向量点击」`是衡量`「语义相似度」`的一种量化方式

举例说明：

<img src="./assets/image-20260201191840909.png" alt="image-20260201191840909" width="90%"/>



### 1.2 向量点积&自注意力

✨ **自注意力（Self-Attention）的核心：让每个 token 根据上下文动态调整自己的语义表示**

自注意力，顾名思义就是：**句子 A → 关注 → 句子 A（自身）**

目的：让 `「每个 token」` 都能与当前句子中的`「其他所有 token」`进行“信息交互”，使其成为融合了上下文信息的新语义表示



举例说明：

<img src="./assets/image-20260201210636048.png" alt="image-20260201210636048" width="90%"/>

### 1.3 自/多头注意力机制中的 Q、K、V 矩阵

> 1.2 小节中的计算方法太简单粗暴了，实际实现并不是这样的，接下来详细介绍Q、K、V矩阵

**自注意力机制（Self-Attention）**、**多头注意力（Multi-Head Attention）** 的核心三要素，就是 Q、K、V矩阵

本质是通过 **向量映射 + 相似度计算** 让模型在处理句子时，能够自适应地关注不同位置的信息，最终加权融合出有意义的输出
\[
\text{Attention}(Q, K, V) = \text{Softmax}\left( \frac{QK^T}{\sqrt{d_k}} \right) V
\]

- **Q (Query，查询)**：当前位置的 “问题”—— 模型想从序列中**找什么？**
- **K (Key，键)**：序列中每个位置的 “答案标签”—— 模型**有什么信息**可以匹配
- **V (Value，值)**：序列中每个位置的 “答案内容”—— 匹配后**实际要使用的信息**

<img src="./assets/image-20260201214807865.png" alt="image-20260201214807865" width="90%"/>





